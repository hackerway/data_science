{"name":"Data Science","tagline":"","body":"Data Science.\r\n=============\r\n\r\nLearning from data in order to gain useful predictions and insights. This course introduces methods for five key facets of an investigation: data wrangling, cleaning, and sampling to get a suitable data set; data management to be able to access big data quickly and reliably; exploratory data analysis to generate hypotheses and intuition; prediction based on statistical methods such as regression and classification; and communication of results through visualization, stories, and interpretable summaries. \r\n\r\nThe course is built around three modules: prediction and elections, recommendation and business analytics, and sampling and social network analysis. We will be using Python for all programming assignments and projects. \r\n\r\nThis class is about learning from data, in order to gain useful predictions and insights. Separating signal from noise presents many computational and inferential challenges, which we approach from a perspective at the interface of computer science and statistics.  Through real-world examples of wide interest, we introduce methods for five key facets of an investigation:\r\n \r\n1. Data munging/scraping/sampling/cleaning in order to get an informative, manageable data set;\r\n2. Data storage and management in order to be able to access data - especially big data - quickly and reliably during subsequent analysis;\r\n3. Exploratory data analysis to generate hypotheses and intuition about the data;\r\n4. Prediction based on statistical tools such as regression, classification, and clustering; and communication of results through visualization, stories, and interpretable summaries.\r\n\r\nExpected Learning Outcomes.\r\n===========================\r\n \r\nAfter successful completion of this course, you will be able to.\r\n \r\n1. Use Python and other tools to scrape, clean, and process data\r\n2. Use data management techniques to store data locally and in cloud infrastructures\r\n3. Use statistical methods and visualization to quickly explore data\r\n4. Apply statistics and computational analysis to make predictions based on data\r\n5. Apply basic computer science concepts such as modularity, abstraction, and encapsulation to data analysis problems\r\n6. Implement data-intensive computations on cluster and cloud infrastructures using MapReduce\r\n7. Effectively communicate the outcome of data analysis using descriptive statistics and visualizations\r\n \r\n \r\nWhat is the structure of the class?\r\n===================================\r\n \r\nThere will be three major modules, each focusing on an important arena in which data science is playing a crucial role. Within each module, we will study how to gather, explore, and analyze relevant data, as well as how to communicate the results. The major programming language used will be Python.\r\n \r\nThe three modules are as follows:\r\n=================================\r\n \r\n1. Prediction and elections module: how did Nate Silver predict 50 out of 50 states correctly in the 2012 U.S. presidential election, and 49 out of 50 correctly in the 2008 election? How much of that was luck? We will discuss how to find, process, combine, visualize, simulate, and summarize election-related data and questions, especially if there are conflicting polls with different reliabilities.\r\n \r\n2. Recommendation and business analytics module: the Neflix Prize was a famous recent example of collaborative filtering: given information about which movies various users have liked and disliked, how should Netflix make recommendations for what movies a user should watch? Many other companies are interested in closely-related problems. Often there is a very large but very sparse data set (e.g., there could be millions of users and tens of thousands of movies, but very few users rate more than a few hundred movies). We will explore techniques for working with such data.\r\n \r\n3. Sampling and social network analysis module: social, biological, and technological networks are attracting interest from many fields. They are examples of relational data, in which there are measurements on pairs of individuals, not just on individuals. But computation and visualization for a network with more than, say, 50 nodes (individuals) presents many challenges in scalability and interpretability. We will study techniques for drawing a sample from a network, for analyzing network data (e.g., finding “communities” and “influential” nodes in the network), and for visualizing network data.\r\n\r\nCode.\r\n=====\r\n\r\n[HW1.ipynb](http://nbviewer.ipython.org/github/noelnamai/DataScience/blob/master/HW1.ipynb?create=1)\r\n----------------------------------------------------------------------------------------------------\r\nPolling data isn't a perfect predictor for the future, and some polls are more accurate than others. This means that election forecastors must consider prediction uncertainty when building models.\r\nIn this first assignment, you will perform a simple analysis of polling data about the upcoming Governor races. The assignment has three main parts:\r\n\r\n1. First you will build some tools to download historical polling data from the web, and parse it into a more convenient format.\r\n2. Next you will use these tools to aggregate and visualize several past Governor races\r\n3. Finally you will run a bootstrap analysis to estimate the probable outcome of current Governor races, given the level of precision of historical polls.\r\n\r\n[HW2.ipynb](http://nbviewer.ipython.org/github/noelnamai/DataScience/blob/master/HW2.ipynb?create=1)\r\n----------------------------------------------------------------------------------------------------\r\nWe are going to focus on the 2012 Presidential election. Analysts like Nate Silver, Drew Linzer, and Sam Wang developed highly accurate models that correctly forecasted most or all of the election outcomes in each of the 50 states. We will explore how hard it is to recreate similarly successful models. The goals of this assignment are:\r\n\r\n1. To practice data manipulation with Pandas.\r\n2. To develop intuition about the interplay of precision, accuracy, and bias when making predictions.\r\n3. To better understand how election forecasts are constructed.\r\n\r\nThe data for our analysis will come from demographic and polling data. We will simulate building our model on October 2, 2012 -- approximately one month before the election.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}