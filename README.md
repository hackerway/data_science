Data Science.
=============

Learning from data in order to gain useful predictions and insights. This course introduces methods for five key facets of an investigation: data wrangling, cleaning, and sampling to get a suitable data set; data management to be able to access big data quickly and reliably; exploratory data analysis to generate hypotheses and intuition; prediction based on statistical methods such as regression and classification; and communication of results through visualization, stories, and interpretable summaries. 

The course is built around three modules: prediction and elections, recommendation and business analytics, and sampling and social network analysis. We will be using Python for all programming assignments and projects. 

This class is about learning from data, in order to gain useful predictions and insights. Separating signal from noise presents many computational and inferential challenges, which we approach from a perspective at the interface of computer science and statistics.  Through real-world examples of wide interest, we introduce methods for five key facets of an investigation:
 
1. Data munging/scraping/sampling/cleaning in order to get an informative, manageable data set;
2. Data storage and management in order to be able to access data - especially big data - quickly and reliably during subsequent analysis;
3. Exploratory data analysis to generate hypotheses and intuition about the data;
4. Prediction based on statistical tools such as regression, classification, and clustering; and communication of results through visualization, stories, and interpretable summaries.

Expected Learning Outcomes.
===========================
 
After successful completion of this course, you will be able to.
 
1. Use Python and other tools to scrape, clean, and process data
2. Use data management techniques to store data locally and in cloud infrastructures
3. Use statistical methods and visualization to quickly explore data
4. Apply statistics and computational analysis to make predictions based on data
5. Apply basic computer science concepts such as modularity, abstraction, and encapsulation to data analysis problems
6. Implement data-intensive computations on cluster and cloud infrastructures using MapReduce
7. Effectively communicate the outcome of data analysis using descriptive statistics and visualizations
 
 
What is the structure of the class?
===================================
 
There will be three major modules, each focusing on an important arena in which data science is playing a crucial role. Within each module, we will study how to gather, explore, and analyze relevant data, as well as how to communicate the results. The major programming language used will be Python.
 
The three modules are as follows:
=================================
 
1. Prediction and elections module: how did Nate Silver predict 50 out of 50 states correctly in the 2012 U.S. presidential election, and 49 out of 50 correctly in the 2008 election? How much of that was luck? We will discuss how to find, process, combine, visualize, simulate, and summarize election-related data and questions, especially if there are conflicting polls with different reliabilities.
 
2. Recommendation and business analytics module: the Neflix Prize was a famous recent example of collaborative filtering: given information about which movies various users have liked and disliked, how should Netflix make recommendations for what movies a user should watch? Many other companies are interested in closely-related problems. Often there is a very large but very sparse data set (e.g., there could be millions of users and tens of thousands of movies, but very few users rate more than a few hundred movies). We will explore techniques for working with such data.
 
3. Sampling and social network analysis module: social, biological, and technological networks are attracting interest from many fields. They are examples of relational data, in which there are measurements on pairs of individuals, not just on individuals. But computation and visualization for a network with more than, say, 50 nodes (individuals) presents many challenges in scalability and interpretability. We will study techniques for drawing a sample from a network, for analyzing network data (e.g., finding “communities” and “influential” nodes in the network), and for visualizing network data.

Code.
=====

[HW1.ipynb](http://nbviewer.ipython.org/github/noelnamai/DataScience/blob/master/HW1.ipynb?create=1)
----------------------------------------------------------------------------------------------------
[HW2.ipynb](http://nbviewer.ipython.org/github/noelnamai/DataScience/blob/master/HW2.ipynb?create=1)
----------------------------------------------------------------------------------------------------
